{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mediapipe_pose_stabilize_v5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anilbhatt1/Skunkworks_Mediapipe_Jitter/blob/main/Mediapipe_pose_stabilize_v5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2PlazN5Q94l"
      },
      "source": [
        "Usage example of MediaPipe Pose Solution API in Python (see also http://solutions.mediapipe.dev/pose)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuQfLvpuJkb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "112e5f08-d4e4-4733-bd78-55510d0d0e32"
      },
      "source": [
        "# Minimum dependency for MediaPipe Solutions Python API is opencv-python\n",
        "!pip install opencv-python~=3.4.11\n",
        "!pip install mediapipe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencv-python~=3.4.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/26/7e65ec6251f385a92801774bcb057f77abfba2c0f58774f78c8a2311de35/opencv_python-3.4.11.45-cp36-cp36m-manylinux2014_x86_64.whl (49.1MB)\n",
            "\u001b[K     |████████████████████████████████| 49.1MB 85kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python~=3.4.11) (1.18.5)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed opencv-python-3.4.11.45\n",
            "Collecting mediapipe\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/08/fba6e69193412507a2e27f83d4c90c5e4b6d42504030ec0b1e8569e463d8/mediapipe-0.8.0-cp36-cp36m-manylinux2014_x86_64.whl (34.5MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5MB 123kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.6/dist-packages (from mediapipe) (3.12.4)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (from mediapipe) (0.35.1)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from mediapipe) (0.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from mediapipe) (0.10.0)\n",
            "Requirement already satisfied: opencv-python<4.0.0,>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from mediapipe) (3.4.11.45)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from mediapipe) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mediapipe) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.11.4->mediapipe) (50.3.2)\n",
            "Installing collected packages: mediapipe\n",
            "Successfully installed mediapipe-0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsGJ9TNsy7hT"
      },
      "source": [
        "lm_dict = {0:'nose',\n",
        "           1:'right_eye_inner', 2:'right_eye', 3:'right_eye_outer',\n",
        "           4:'left_eye_inner', 5:'left_eye', 6:'left_eye_outer',\n",
        "           7:'right_ear', 8:'left_ear',\n",
        "           9:'right_mouth',10:'left_mouth',\n",
        "           11:'right_shoulder', 12:'left:shoulder',\n",
        "           13:'right_elbow', 14:'left_elbow',\n",
        "           15:'right_wrist', 16:'left_wrist',\n",
        "           17: 'right_pinky', 18:'left_pinky',\n",
        "           19:'right_index', 20:'left_index',\n",
        "           21:'right_thumb', 22:'left_thumb',\n",
        "           23:'right_hip', 24:'left_hip'}\n",
        "\n",
        "lm_cnt = 25\n",
        "thresh = 0.03\n",
        "delta_init = {'nose':[0,0],\n",
        "              'right_eye_inner':[0,0], 'right_eye':[0,0], 'right_eye_outer':[0,0],\n",
        "              'left_eye_inner':[0,0],  'left_eye':[0,0],  'left_eye_outer':[0,0],\n",
        "              'right_ear':[0,0], 'left_ear':[0,0],\n",
        "              'right_mouth':[0,0], 'left_mouth':[0,0],\n",
        "              'right_shoulder':[0,0], 'left_shoulder':[0,0],\n",
        "              'right_elbow':[0,0], 'left_elbow':[0,0],\n",
        "              'right_wrist':[0,0], 'left_wrist':[0,0],\n",
        "              'right_pinky':[0,0], 'left_pinky':[0,0],\n",
        "              'right_index':[0,0], 'left_index':[0,0],\n",
        "              'right_thumb':[0,0], 'left_thumb':[0,0],\n",
        "              'right_hip':[0,0], 'left_hip':[0,0]}\n",
        "\n",
        "frame_cnt = 0\n",
        "prev_lst, curr_lst            =  [], []\n",
        "lst = [0,0]\n",
        "for i in range(lm_cnt):\n",
        "    prev_lst.append(lst)\n",
        "    curr_lst.append(lst)\n",
        "face_pts = 9      # Landmarks 0-8 belongs to face comprising of eyes, nose & ears"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKz6ix2eNO11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "590c0298-b6d1-4541-f340-faaaa5055605"
      },
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_pose    = mp.solutions.pose\n",
        "\n",
        "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "#cap = cv2.VideoCapture('/content/9secs_avi.avi')\n",
        "#cap = cv2.VideoCapture('/content/4secs_avi.avi')\n",
        "#cap = cv2.VideoCapture('/content/2secs_avi.avi')\n",
        "cap = cv2.VideoCapture('/content/MostPoses_LR_Full_avi.avi')\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "#out = cv2.VideoWriter('/content/9secs_pose_v12_0.03.avi',fourcc, 20.0, (352,640))\n",
        "#out = cv2.VideoWriter('/content/4secs_pose_v11_0.03.avi',fourcc, 20.0, (1080,1920))\n",
        "#out = cv2.VideoWriter('/content/2secs_pose_v11_0.00.avi',fourcc, 20.0, (720,1280))\n",
        "out = cv2.VideoWriter('/content/MostPoses_LR_Full_v1_0.03.avi',fourcc, 20.0, (640,480))\n",
        "\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret==True:\n",
        "        frame_cnt += 1\n",
        "        image = cv2.cvtColor(cv2.flip(frame, 1), cv2.COLOR_BGR2RGB)\n",
        "        image.flags.writeable = False\n",
        "\n",
        "        results = pose.process(image)\n",
        "\n",
        "        image.flags.writeable = True\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "        \n",
        "        delta_dict = delta_init\n",
        "\n",
        "        # Copying landmarks that we got from model to curr_lst for delta calculation below\n",
        "        for i in range(lm_cnt):\n",
        "            lst = [results.pose_landmarks.landmark[i].x, results.pose_landmarks.landmark[i].y]\n",
        "            curr_lst[i] = lst\n",
        "        \n",
        "        if frame_cnt > 1:\n",
        "\n",
        "            # Calculating delta value of coordinates for all 25 landmarks for current frame            \n",
        "            for i in range(lm_cnt): \n",
        "                delta                = [ abs(curr_lst[i][0] - prev_lst[i][0]) / prev_lst[i][0], abs(curr_lst[i][1] - prev_lst[i][1]) / prev_lst[i][1] ]\n",
        "                delta_dict[lm_dict[i]] = delta\n",
        "\n",
        "            # Checking face. If left_eye-nose or right_eye-nose combination delta stays within threshold, then retain landmarks from previous frame for entire face.    \n",
        "            left_eye_nose_x  = (delta_dict['nose'][0] < thresh and delta_dict['left_eye'][0] < thresh)\n",
        "            left_eye_nose_y  = (delta_dict['nose'][1] < thresh and delta_dict['left_eye'][1] < thresh)\n",
        "\n",
        "            right_eye_nose_x = (delta_dict['nose'][0] < thresh and delta_dict['right_eye'][0] < thresh)\n",
        "            right_eye_nose_y = (delta_dict['nose'][1] < thresh and delta_dict['right_eye'][1] < thresh)\n",
        "\n",
        "            if (left_eye_nose_x or right_eye_nose_x):\n",
        "                for i in range(face_pts):\n",
        "                    results.pose_landmarks.landmark[i].x  = prev_lst[i][0]\n",
        "\n",
        "            if (left_eye_nose_y or right_eye_nose_y):\n",
        "                for i in range(face_pts):\n",
        "                    results.pose_landmarks.landmark[i].y  = prev_lst[i][1]\n",
        "\n",
        "            # Checking mouth. If delta value stays within threshold, then retain landmarks from previous frame.\n",
        "            if delta_dict['right_mouth'][0] < thresh:\n",
        "                results.pose_landmarks.landmark[9].x  = prev_lst[9][0]   # 9 - right_mouth\n",
        "            if delta_dict['right_mouth'][1] < thresh:\n",
        "                results.pose_landmarks.landmark[9].y  = prev_lst[9][1]\n",
        "\n",
        "            if delta_dict['left_mouth'][0] < thresh:\n",
        "                results.pose_landmarks.landmark[10].x  = prev_lst[10][0]   # 10 - left_mouth                                                       \n",
        "            if delta_dict['left_mouth'][1] < thresh:\n",
        "                results.pose_landmarks.landmark[10].y  = prev_lst[10][1]\n",
        "\n",
        "            # Checking shoulders. If either right shoulder OR left shoulder delta stays within threshold, then retain landmarks from previous frame for both.\n",
        "            shoulder_x = (delta_dict['right_shoulder'][0] < thresh or delta_dict['left_shoulder'][0] < thresh)\n",
        "            shoulder_y = (delta_dict['right_shoulder'][1] < thresh or delta_dict['left_shoulder'][1] < thresh)\n",
        "\n",
        "            if shoulder_x:\n",
        "                results.pose_landmarks.landmark[11].x  = prev_lst[11][0]    # 11 - right_shoulder               \n",
        "                results.pose_landmarks.landmark[12].x  = prev_lst[12][0]    # 12 - left_shoulder\n",
        "            if shoulder_y:\n",
        "                results.pose_landmarks.landmark[11].y  = prev_lst[11][1]                  \n",
        "                results.pose_landmarks.landmark[12].y  = prev_lst[12][1]\n",
        "\n",
        "            # Checking elbows.If delta value within threshold, then retain landmarks from previous frame.\n",
        "            if delta_dict['right_elbow'][0] < thresh:\n",
        "                results.pose_landmarks.landmark[13].x  = prev_lst[13][0]       # 13 - right_elbow\n",
        "            if delta_dict['right_elbow'][1] < thresh:\n",
        "                results.pose_landmarks.landmark[13].y  = prev_lst[13][1]      \n",
        "\n",
        "            if delta_dict['left_elbow'][0] < thresh:\n",
        "                results.pose_landmarks.landmark[14].x  = prev_lst[14][0]       # 14 - left_elbow     \n",
        "            if delta_dict['left_elbow'][1] < thresh:\n",
        "                results.pose_landmarks.landmark[14].y  = prev_lst[14][1]      \n",
        "\n",
        "            # Checking right_arm. If right_wrist delta remains within threshold value, then retain the landmarks from previous frame for entire right_arm.\n",
        "            if delta_dict['right_wrist'][0] < thresh:\n",
        "                results.pose_landmarks.landmark[15].x  = prev_lst[15][0]       # 15 - right_wrist\n",
        "                results.pose_landmarks.landmark[17].x  = prev_lst[17][0]       # 17 - right_pinky\n",
        "                results.pose_landmarks.landmark[19].x  = prev_lst[19][0]       # 19 - right_index\n",
        "                results.pose_landmarks.landmark[21].x  = prev_lst[21][0]       # 21 - right_thumb  \n",
        "\n",
        "            if delta_dict['right_wrist'][1] < thresh:\n",
        "                results.pose_landmarks.landmark[15].y  = prev_lst[15][1]       # 15 - right_wrist\n",
        "                results.pose_landmarks.landmark[17].y  = prev_lst[17][1]       # 17 - right_pinky\n",
        "                results.pose_landmarks.landmark[19].y  = prev_lst[19][1]       # 19 - right_index\n",
        "                results.pose_landmarks.landmark[21].y  = prev_lst[21][1]       # 21 - right_thumb\n",
        "\n",
        "            # Checking left_arm. If left_wrist delta remains within threshold value, then retain the landmarks from previous frame for entire left_arm.\n",
        "            if delta_dict['left_wrist'][0] < thresh:\n",
        "                results.pose_landmarks.landmark[16].x  = prev_lst[16][0]       # 16 - left_wrist\n",
        "                results.pose_landmarks.landmark[18].x  = prev_lst[18][0]       # 18 - left_pinky\n",
        "                results.pose_landmarks.landmark[20].x  = prev_lst[20][0]       # 20 - left_index\n",
        "                results.pose_landmarks.landmark[22].x  = prev_lst[22][0]       # 22 - left_thumb  \n",
        "\n",
        "            if delta_dict['left_wrist'][1] < thresh:\n",
        "                results.pose_landmarks.landmark[16].y  = prev_lst[16][1]       # 16 - left_wrist\n",
        "                results.pose_landmarks.landmark[18].y  = prev_lst[18][1]       # 18 - left_pinky\n",
        "                results.pose_landmarks.landmark[20].y  = prev_lst[20][1]       # 20 - left_index\n",
        "                results.pose_landmarks.landmark[22].y  = prev_lst[22][1]       # 22 - left_thumb\n",
        "                                                                                                        \n",
        "            # Checking Hips. If either right hip OR left hip delta stays within threshold, then retain landmarks from previous frame for both.\n",
        "            hip_x = (delta_dict['right_hip'][0] < thresh or delta_dict['left_hip'][0] < thresh)\n",
        "            hip_y = (delta_dict['right_hip'][1] < thresh or delta_dict['left_hip'][1] < thresh)\n",
        "\n",
        "            if hip_x:\n",
        "                results.pose_landmarks.landmark[23].x  = prev_lst[23][0]    # 23 - right_hip\n",
        "                results.pose_landmarks.landmark[24].x  = prev_lst[24][0]    # 24 - left_hip\n",
        "            if hip_y:\n",
        "                results.pose_landmarks.landmark[23].y  = prev_lst[23][1]                  \n",
        "                results.pose_landmarks.landmark[24].y  = prev_lst[24][1]\n",
        "\n",
        "        # Copying landmarks that we got from model/modified to prev_lst for comparison of next frame\n",
        "        for i in range(lm_cnt):\n",
        "            lst = [results.pose_landmarks.landmark[i].x, results.pose_landmarks.landmark[i].y]\n",
        "            prev_lst[i] = lst\n",
        "\n",
        "        # Connecting the landmarks\n",
        "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "        out.write(image)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    else:\n",
        "        print('End of Frame # :', frame_cnt)\n",
        "        break\n",
        "\n",
        "# Release everything if job is finished\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "End of Frame # : 941\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCJX0y2u6RhI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}